{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "processed-stations",
   "metadata": {},
   "source": [
    "## Notebook to retrieve IWP from GMI TB and other auxiliary data using QRNN, uses quantNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "funky-outdoors",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import ipywidgets as w\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import netCDF4\n",
    "from matplotlib.ticker import (MultipleLocator, FormatStrFormatter,\n",
    "                               AutoMinorLocator)\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from iwc2tb.GMI.gmiData import gmiData\n",
    "import os\n",
    "import time\n",
    "from quantnn.models.pytorch.fully_connected import FullyConnected\n",
    "from torch import optim\n",
    "from quantnn.qrnn import QRNN\n",
    "from torch.optim import Adam\n",
    "from quantnn.metrics import ScatterPlot\n",
    "from quantnn.models.pytorch.logging import TensorBoardLogger\n",
    "from quantnn.transformations import LogLinear, Log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conditional-salon",
   "metadata": {},
   "source": [
    "### Set Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "specialized-shooting",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles         = np.linspace(0.01, 0.99, 128)\n",
    "\n",
    "batchSize         = 256\n",
    "\n",
    "\n",
    "n_layers          = 5\n",
    "n_neurons         = 256\n",
    "\n",
    "\n",
    "inputs            = np.array([\"ta\", \"t2m\",  \"wvp\", \"z0\", \"stype\"])\n",
    "ninputs           = len(inputs) + 3 + 10\n",
    "\n",
    "outputs           = \"iwp\"\n",
    "\n",
    "latlims           = [0, 65]\n",
    "\n",
    "filename          = \"qrnn_gmi_adam_sgd.nc\"\n",
    "outputfile        = os.path.join(os.path.expanduser(\"~/Dendrite/Projects/IWP/GMI/training_data/try_training/\"), \n",
    "                                                    filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "martial-corpus",
   "metadata": {},
   "source": [
    "## read in training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "returning-bibliography",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625\n"
     ]
    }
   ],
   "source": [
    "data = gmiData(os.path.expanduser(\"~/Dendrite/Projects/IWP/GMI/training_data/TB_GMI_train.nc\"), \n",
    "               inputs, outputs, latlims = latlims,\n",
    "               batch_size = batchSize)  \n",
    "\n",
    "n = len(data)\n",
    "n_train = int(0.9 * n)\n",
    "n_val = n - n_train\n",
    "\n",
    "training_data, validation_data = random_split(data, [n_train, n_val])\n",
    "results = []\n",
    "\n",
    "print(len(validation_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-semester",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/inderpreet/git/quantnn/quantnn/metrics.py:566: RuntimeWarning: invalid value encountered in true_divide\n",
      "  img /= norm\n",
      "/home/inderpreet/git/quantnn/quantnn/metrics.py:566: RuntimeWarning: invalid value encountered in true_divide\n",
      "  img /= norm\n",
      "/home/inderpreet/git/quantnn/quantnn/metrics.py:566: RuntimeWarning: invalid value encountered in true_divide\n",
      "  img /= norm\n",
      "/home/inderpreet/git/quantnn/quantnn/metrics.py:566: RuntimeWarning: invalid value encountered in true_divide\n",
      "  img /= norm\n",
      "/home/inderpreet/git/quantnn/quantnn/metrics.py:566: RuntimeWarning: invalid value encountered in true_divide\n",
      "  img /= norm\n",
      "/home/inderpreet/git/quantnn/quantnn/metrics.py:566: RuntimeWarning: invalid value encountered in true_divide\n",
      "  img /= norm\n",
      "/home/inderpreet/git/quantnn/quantnn/metrics.py:566: RuntimeWarning: invalid value encountered in true_divide\n",
      "  img /= norm\n",
      "/home/inderpreet/git/quantnn/quantnn/metrics.py:566: RuntimeWarning: invalid value encountered in true_divide\n",
      "  img /= norm\n",
      "/home/inderpreet/git/quantnn/quantnn/metrics.py:566: RuntimeWarning: invalid value encountered in true_divide\n",
      "  img /= norm\n",
      "/home/inderpreet/git/quantnn/quantnn/metrics.py:566: RuntimeWarning: invalid value encountered in true_divide\n",
      "  img /= norm\n",
      "/home/inderpreet/git/quantnn/quantnn/metrics.py:566: RuntimeWarning: invalid value encountered in true_divide\n",
      "  img /= norm\n",
      "/home/inderpreet/git/quantnn/quantnn/metrics.py:566: RuntimeWarning: invalid value encountered in true_divide\n",
      "  img /= norm\n",
      "/home/inderpreet/git/quantnn/quantnn/metrics.py:566: RuntimeWarning: invalid value encountered in true_divide\n",
      "  img /= norm\n",
      "/home/inderpreet/git/quantnn/quantnn/metrics.py:566: RuntimeWarning: invalid value encountered in true_divide\n",
      "  img /= norm\n",
      "/home/inderpreet/git/quantnn/quantnn/metrics.py:566: RuntimeWarning: invalid value encountered in true_divide\n",
      "  img /= norm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                                                           </span>\n",
       "<span style=\"font-style: italic\">                                                                                           </span>\n",
       "<span style=\"font-style: italic\">                                      Training history                                     </span>\n",
       "<span style=\"font-style: italic\">                                                                                           </span>\n",
       "                                                                                           \n",
       " <span style=\"font-weight: bold\">      Epoch      </span> <span style=\"font-weight: bold\"> </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">  Training loss  </span><span style=\"font-weight: bold\"> </span> <span style=\"font-weight: bold\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> Validation loss </span><span style=\"font-weight: bold\"> </span> <span style=\"font-weight: bold\"> </span><span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\">  MSE   </span><span style=\"font-weight: bold\"> </span> <span style=\"font-weight: bold\"> </span><span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\"> Bias  </span><span style=\"font-weight: bold\"> </span> <span style=\"font-weight: bold\"> </span><span style=\"color: #af00ff; text-decoration-color: #af00ff; font-weight: bold\">  CRPS  </span><span style=\"font-weight: bold\"> </span> \n",
       " ───────────────────────────────────────────────────────────────────────────────────────── \n",
       "     <span style=\"font-weight: bold\">#</span>      LR            <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Total</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Total</span>                                        \n",
       "                                                                                           \n",
       "    <span style=\"font-weight: bold\">  1</span>   0.0010          <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.201</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.192</span>         <span style=\"color: #af00ff; text-decoration-color: #af00ff\">1.081   </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.204  </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.378   </span>  \n",
       "    <span style=\"font-weight: bold\">  2</span>   0.0010          <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.183</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.180</span>         <span style=\"color: #af00ff; text-decoration-color: #af00ff\">1.050   </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">-0.011 </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.347   </span>  \n",
       "    <span style=\"font-weight: bold\">  3</span>   0.0010          <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.176</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.172</span>         <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.898   </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">-0.024 </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.336   </span>  \n",
       "    <span style=\"font-weight: bold\">  4</span>   0.0009          <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.171</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.165</span>         <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.885   </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">-0.050 </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.321   </span>  \n",
       "    <span style=\"font-weight: bold\">  5</span>   0.0008          <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.168</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.157</span>         <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.766   </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.022  </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.303   </span>  \n",
       "    <span style=\"font-weight: bold\">  6</span>   0.0008          <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.164</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.158</span>         <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.806   </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">-0.015 </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.309   </span>  \n",
       "    <span style=\"font-weight: bold\">  7</span>   0.0007          <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.159</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.151</span>         <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.720   </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">-0.013 </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.305   </span>  \n",
       "    <span style=\"font-weight: bold\">  8</span>   0.0006          <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.158</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.159</span>         <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.860   </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">-0.129 </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.306   </span>  \n",
       "    <span style=\"font-weight: bold\">  9</span>   0.0004          <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.153</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.148</span>         <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.708   </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">-0.016 </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.295   </span>  \n",
       "    <span style=\"font-weight: bold\"> 10</span>   0.0003          <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.150</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.143</span>         <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.675   </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">-0.007 </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.282   </span>  \n",
       "    <span style=\"font-weight: bold\"> 11</span>   0.0003          <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.148</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.144</span>         <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.712   </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">-0.057 </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.285   </span>  \n",
       "    <span style=\"font-weight: bold\"> 12</span>   0.0002          <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.143</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.140</span>         <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.684   </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.012  </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.279   </span>  \n",
       "    <span style=\"font-weight: bold\"> 13</span>   0.0001          <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.142</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.141</span>         <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.648   </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">-0.008 </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.276   </span>  \n",
       "    <span style=\"font-weight: bold\"> 14</span>   0.0000          <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.140</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.141</span>         <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.671   </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">-0.007 </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.280   </span>  \n",
       "    <span style=\"font-weight: bold\"> 15</span>   0.0000          <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.139</span>               <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.138</span>         <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.622   </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">-0.003 </span>   <span style=\"color: #af00ff; text-decoration-color: #af00ff\">0.271   </span>  \n",
       "                                                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                                                                           \u001b[0m\n",
       "\u001b[3m                                                                                           \u001b[0m\n",
       "\u001b[3m                                      Training history                                     \u001b[0m\n",
       "\u001b[3m                                                                                           \u001b[0m\n",
       "                                                                                           \n",
       " \u001b[1m \u001b[0m\u001b[1m     Epoch     \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1;31m  Training loss  \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1;34m Validation loss \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1;38;5;129m  MSE   \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1;38;5;129m Bias  \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1;38;5;129m  CRPS  \u001b[0m\u001b[1m \u001b[0m \n",
       " ───────────────────────────────────────────────────────────────────────────────────────── \n",
       "     \u001b[1m#\u001b[0m      LR            \u001b[1;31mTotal\u001b[0m               \u001b[1;34mTotal\u001b[0m                                        \n",
       "                                                                                           \n",
       "    \u001b[1m  1\u001b[0m   0.0010          \u001b[1;31m0.201\u001b[0m               \u001b[1;34m0.192\u001b[0m         \u001b[38;5;129m1.081\u001b[0m\u001b[38;5;129m   \u001b[0m   \u001b[38;5;129m0.204\u001b[0m\u001b[38;5;129m  \u001b[0m   \u001b[38;5;129m0.378\u001b[0m\u001b[38;5;129m   \u001b[0m  \n",
       "    \u001b[1m  2\u001b[0m   0.0010          \u001b[1;31m0.183\u001b[0m               \u001b[1;34m0.180\u001b[0m         \u001b[38;5;129m1.050\u001b[0m\u001b[38;5;129m   \u001b[0m   \u001b[38;5;129m-0.011\u001b[0m\u001b[38;5;129m \u001b[0m   \u001b[38;5;129m0.347\u001b[0m\u001b[38;5;129m   \u001b[0m  \n",
       "    \u001b[1m  3\u001b[0m   0.0010          \u001b[1;31m0.176\u001b[0m               \u001b[1;34m0.172\u001b[0m         \u001b[38;5;129m0.898\u001b[0m\u001b[38;5;129m   \u001b[0m   \u001b[38;5;129m-0.024\u001b[0m\u001b[38;5;129m \u001b[0m   \u001b[38;5;129m0.336\u001b[0m\u001b[38;5;129m   \u001b[0m  \n",
       "    \u001b[1m  4\u001b[0m   0.0009          \u001b[1;31m0.171\u001b[0m               \u001b[1;34m0.165\u001b[0m         \u001b[38;5;129m0.885\u001b[0m\u001b[38;5;129m   \u001b[0m   \u001b[38;5;129m-0.050\u001b[0m\u001b[38;5;129m \u001b[0m   \u001b[38;5;129m0.321\u001b[0m\u001b[38;5;129m   \u001b[0m  \n",
       "    \u001b[1m  5\u001b[0m   0.0008          \u001b[1;31m0.168\u001b[0m               \u001b[1;34m0.157\u001b[0m         \u001b[38;5;129m0.766\u001b[0m\u001b[38;5;129m   \u001b[0m   \u001b[38;5;129m0.022\u001b[0m\u001b[38;5;129m  \u001b[0m   \u001b[38;5;129m0.303\u001b[0m\u001b[38;5;129m   \u001b[0m  \n",
       "    \u001b[1m  6\u001b[0m   0.0008          \u001b[1;31m0.164\u001b[0m               \u001b[1;34m0.158\u001b[0m         \u001b[38;5;129m0.806\u001b[0m\u001b[38;5;129m   \u001b[0m   \u001b[38;5;129m-0.015\u001b[0m\u001b[38;5;129m \u001b[0m   \u001b[38;5;129m0.309\u001b[0m\u001b[38;5;129m   \u001b[0m  \n",
       "    \u001b[1m  7\u001b[0m   0.0007          \u001b[1;31m0.159\u001b[0m               \u001b[1;34m0.151\u001b[0m         \u001b[38;5;129m0.720\u001b[0m\u001b[38;5;129m   \u001b[0m   \u001b[38;5;129m-0.013\u001b[0m\u001b[38;5;129m \u001b[0m   \u001b[38;5;129m0.305\u001b[0m\u001b[38;5;129m   \u001b[0m  \n",
       "    \u001b[1m  8\u001b[0m   0.0006          \u001b[1;31m0.158\u001b[0m               \u001b[1;34m0.159\u001b[0m         \u001b[38;5;129m0.860\u001b[0m\u001b[38;5;129m   \u001b[0m   \u001b[38;5;129m-0.129\u001b[0m\u001b[38;5;129m \u001b[0m   \u001b[38;5;129m0.306\u001b[0m\u001b[38;5;129m   \u001b[0m  \n",
       "    \u001b[1m  9\u001b[0m   0.0004          \u001b[1;31m0.153\u001b[0m               \u001b[1;34m0.148\u001b[0m         \u001b[38;5;129m0.708\u001b[0m\u001b[38;5;129m   \u001b[0m   \u001b[38;5;129m-0.016\u001b[0m\u001b[38;5;129m \u001b[0m   \u001b[38;5;129m0.295\u001b[0m\u001b[38;5;129m   \u001b[0m  \n",
       "    \u001b[1m 10\u001b[0m   0.0003          \u001b[1;31m0.150\u001b[0m               \u001b[1;34m0.143\u001b[0m         \u001b[38;5;129m0.675\u001b[0m\u001b[38;5;129m   \u001b[0m   \u001b[38;5;129m-0.007\u001b[0m\u001b[38;5;129m \u001b[0m   \u001b[38;5;129m0.282\u001b[0m\u001b[38;5;129m   \u001b[0m  \n",
       "    \u001b[1m 11\u001b[0m   0.0003          \u001b[1;31m0.148\u001b[0m               \u001b[1;34m0.144\u001b[0m         \u001b[38;5;129m0.712\u001b[0m\u001b[38;5;129m   \u001b[0m   \u001b[38;5;129m-0.057\u001b[0m\u001b[38;5;129m \u001b[0m   \u001b[38;5;129m0.285\u001b[0m\u001b[38;5;129m   \u001b[0m  \n",
       "    \u001b[1m 12\u001b[0m   0.0002          \u001b[1;31m0.143\u001b[0m               \u001b[1;34m0.140\u001b[0m         \u001b[38;5;129m0.684\u001b[0m\u001b[38;5;129m   \u001b[0m   \u001b[38;5;129m0.012\u001b[0m\u001b[38;5;129m  \u001b[0m   \u001b[38;5;129m0.279\u001b[0m\u001b[38;5;129m   \u001b[0m  \n",
       "    \u001b[1m 13\u001b[0m   0.0001          \u001b[1;31m0.142\u001b[0m               \u001b[1;34m0.141\u001b[0m         \u001b[38;5;129m0.648\u001b[0m\u001b[38;5;129m   \u001b[0m   \u001b[38;5;129m-0.008\u001b[0m\u001b[38;5;129m \u001b[0m   \u001b[38;5;129m0.276\u001b[0m\u001b[38;5;129m   \u001b[0m  \n",
       "    \u001b[1m 14\u001b[0m   0.0000          \u001b[1;31m0.140\u001b[0m               \u001b[1;34m0.141\u001b[0m         \u001b[38;5;129m0.671\u001b[0m\u001b[38;5;129m   \u001b[0m   \u001b[38;5;129m-0.007\u001b[0m\u001b[38;5;129m \u001b[0m   \u001b[38;5;129m0.280\u001b[0m\u001b[38;5;129m   \u001b[0m  \n",
       "    \u001b[1m 15\u001b[0m   0.0000          \u001b[1;31m0.139\u001b[0m               \u001b[1;34m0.138\u001b[0m         \u001b[38;5;129m0.622\u001b[0m\u001b[38;5;129m   \u001b[0m   \u001b[38;5;129m-0.003\u001b[0m\u001b[38;5;129m \u001b[0m   \u001b[38;5;129m0.271\u001b[0m\u001b[38;5;129m   \u001b[0m  \n",
       "                                                                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d740ca9ba07a4d1e85028c41ff940f4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/inderpreet/git/quantnn/quantnn/metrics.py:566: RuntimeWarning: invalid value encountered in true_divide\n",
      "  img /= norm\n",
      "/home/inderpreet/git/quantnn/quantnn/metrics.py:566: RuntimeWarning: invalid value encountered in true_divide\n",
      "  img /= norm\n",
      "/home/inderpreet/git/quantnn/quantnn/metrics.py:566: RuntimeWarning: invalid value encountered in true_divide\n",
      "  img /= norm\n",
      "/home/inderpreet/git/quantnn/quantnn/metrics.py:566: RuntimeWarning: invalid value encountered in true_divide\n",
      "  img /= norm\n",
      "/home/inderpreet/git/quantnn/quantnn/metrics.py:566: RuntimeWarning: invalid value encountered in true_divide\n",
      "  img /= norm\n",
      "/home/inderpreet/git/quantnn/quantnn/metrics.py:566: RuntimeWarning: invalid value encountered in true_divide\n",
      "  img /= norm\n",
      "/home/inderpreet/git/quantnn/quantnn/metrics.py:566: RuntimeWarning: invalid value encountered in true_divide\n",
      "  img /= norm\n",
      "/home/inderpreet/git/quantnn/quantnn/metrics.py:566: RuntimeWarning: invalid value encountered in true_divide\n",
      "  img /= norm\n",
      "/home/inderpreet/git/quantnn/quantnn/metrics.py:566: RuntimeWarning: invalid value encountered in true_divide\n",
      "  img /= norm\n",
      "/home/inderpreet/git/quantnn/quantnn/metrics.py:566: RuntimeWarning: invalid value encountered in true_divide\n",
      "  img /= norm\n",
      "/home/inderpreet/git/quantnn/quantnn/metrics.py:566: RuntimeWarning: invalid value encountered in true_divide\n",
      "  img /= norm\n",
      "/home/inderpreet/git/quantnn/quantnn/metrics.py:566: RuntimeWarning: invalid value encountered in true_divide\n",
      "  img /= norm\n",
      "/home/inderpreet/git/quantnn/quantnn/metrics.py:566: RuntimeWarning: invalid value encountered in true_divide\n",
      "  img /= norm\n"
     ]
    }
   ],
   "source": [
    "transform         = LogLinear()\n",
    "\n",
    "skip_connections  = True\n",
    "batch_norm        = True\n",
    "\n",
    "skip_connections  = True\n",
    "batch_norm        = True\n",
    "\n",
    "model             = FullyConnected(ninputs,\n",
    "                       quantiles.size,\n",
    "                       n_layers,\n",
    "                       n_neurons,\n",
    "                       skip_connections=skip_connections,\n",
    "                       batch_norm=batch_norm)\n",
    "\n",
    "\n",
    "qrnn             = QRNN(quantiles=quantiles, model=model) # no tranform defined\n",
    "\n",
    "metrics          = [\"MeanSquaredError\", \"Bias\", \"CRPS\", \"CalibrationPlot\"]\n",
    "\n",
    "logger = TensorBoardLogger(n_epochs)\n",
    "\n",
    "# or by directly providing a metric object (If there are configuration parameters to set).\n",
    "scatter_plot    = ScatterPlot(bins=np.logspace(-2, 2, 21), log_scale=True)\n",
    "metrics.append(scatter_plot)\n",
    "\n",
    "for lr, n_epochs in zip([1e-3, 1e-4], [15, 20]):\n",
    "    \n",
    "    optimizer = Adam(qrnn.model.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, n_epochs)\n",
    "\n",
    "    qrnn.train(training_data=training_data,\n",
    "               validation_data=validation_data,\n",
    "               n_epochs=n_epochs,\n",
    "               mask=-1,\n",
    "               device=\"cpu\",\n",
    "               logger=logger,\n",
    "               metrics=metrics,\n",
    "               optimizer=optimizer, \n",
    "               scheduler=scheduler,\n",
    "              );\n",
    "\n",
    "qrnn.save(outputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cathedral-supplement",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook analyses the IWP retreived using QRNN. Uses test data (simulations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import ipywidgets as w\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import netCDF4\n",
    "from matplotlib.ticker import (MultipleLocator, FormatStrFormatter,\n",
    "                               AutoMinorLocator)\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from iwc2tb.GMI.gmiData import gmiData\n",
    "from iwc2tb.GMI.GOES import GOES\n",
    "import os\n",
    "from mpl_toolkits.basemap import Basemap, cm\n",
    "import numpy.ma as ma\n",
    "from iwc2tb.common.hist2d import hist2d\n",
    "from iwc2tb.common.plot_locations_map import plot_locations_map\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib import cm\n",
    "#from typhon.retrieval.qrnn import set_backend, QRNN\n",
    "#set_backend(\"pytorch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize          = 256\n",
    "inputs             = np.array( [\"ta\", \"t2m\",  \"wvp\", \"z0\", \"lat\", \"stype\"])\n",
    "ninputs            = len(inputs) + 3\n",
    "outputs            = \"iwp\"\n",
    "xlog               = True\n",
    "latlims            = [0, 45]\n",
    "latlims            = [0, 65]\n",
    "#quantiles          = np.arange(0.05, 1, 0.05)\n",
    "quantiles         = np.linspace(0.01, 0.99, 50)\n",
    "imedian            = np.argwhere((quantiles >= 0.49) & (quantiles < 0.51))[0][0]\n",
    "\n",
    "\n",
    "\n",
    "filename = '~/Dendrite/Projects/IWP/GMI/training_data/try_training/qrnn_gmi_nn_lpa_v1.nc'\n",
    "\n",
    "#filename = '~/Dendrite/Projects/IWP/GMI/training_data/try_training/qrnn_gmi_all_hotencode.nc'\n",
    "\n",
    "\n",
    "\n",
    "training_data      = gmiData(os.path.expanduser(\"~/Dendrite/Projects/IWP/GMI/training_data/TB_GMI_train_jan_esa.nc\"), \n",
    "                             inputs, \n",
    "                             outputs,\n",
    "                             batch_size = batchSize,\n",
    "                             latlims = latlims,)\n",
    "                             #log_iwp = xlog)\n",
    "\n",
    "norm = training_data.norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "validation_data    = gmiData(os.path.expanduser(\"~/Dendrite/Projects/IWP/GMI/training_data/TB_GMI_train_jan_pr_aro_new.nc\"), \n",
    "                             inputs,\n",
    "                             outputs,\n",
    "                             batch_size = batchSize,\n",
    "                             latlims = latlims,\n",
    "                             normalise = norm,)\n",
    "                             #log_iwp = xlog)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_mean(validation_data, qrnn, quantiles, log = False):\n",
    "    y          = []\n",
    "    y_pos_mean = []\n",
    "    y_pre      = []\n",
    "    x_in       = []\n",
    "\n",
    "    nbatch = len(validation_data)\n",
    "    for i in range(nbatch):\n",
    "\n",
    "        xx, yy = validation_data[i]\n",
    "        x = xx.detach().numpy() \n",
    "        y_pre.append(qrnn.predict(xx)) \n",
    "        #y_pos_mean.append((posterior_mean(x, qrnn, quantiles, log)))\n",
    "        y_pos_mean.append(qrnn.posterior_mean(xx))\n",
    "        y.append(yy.detach().numpy())\n",
    "        x_in.append(x)\n",
    "\n",
    "    y_pre = np.concatenate(y_pre, axis = 0)\n",
    "    y = np.concatenate(y, axis= 0)\n",
    "    y_pos_mean = np.concatenate(y_pos_mean, axis = 0) \n",
    "    \n",
    "    #if log == True:\n",
    "    #    y      = np.exp(y)\n",
    "    #    y_pre  = np.exp(y_pre)\n",
    "\n",
    "        \n",
    "    return y, y_pre, y_pos_mean\n",
    "\n",
    "def cdf(x, qrnn, quantiles, log = False):\n",
    "    if len(x.shape) > 1:\n",
    "        s = x.shape[:-1] + (quantiles.size + 2,)\n",
    "    else:\n",
    "        s = (1, quantiles.size + 2)\n",
    "\n",
    "    y_pred = np.zeros(s)\n",
    "    pre    = qrnn.predict(x)\n",
    "    \n",
    "    if log == True:\n",
    "        pre = np.exp(pre)\n",
    "        \n",
    "    y_pred[:, 1:-1] = pre\n",
    "\n",
    "    y_pred[:, 0] = 2.0 * y_pred[:, 1] - y_pred[:, 2]\n",
    "    y_pred[:, -1] = 2.0 * y_pred[:, -2] - y_pred[:, -3]\n",
    "\n",
    "    qs = np.zeros(quantiles.size + 2)\n",
    "    qs[1:-1] = quantiles\n",
    "    qs[0] = 0.0\n",
    "    qs[-1] = 1.0\n",
    "\n",
    "    return y_pred, qs\n",
    "\n",
    "\n",
    "def posterior_mean(x, qrnn, quantiles, log = False):\n",
    "    y_pred, qs = cdf(x, qrnn, quantiles, log)\n",
    "    mus = y_pred[:, -1] - np.trapz(qs, x=y_pred)\n",
    "    return mus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: (268.5954546635614, 20.275572694774606),\n",
       " 1: (265.01122187242123, 23.294676778521556),\n",
       " 2: (265.47096955555645, 13.746809194371663),\n",
       " 3: (257.07374133613956, 9.433577286174387),\n",
       " 4: (286.3308850128538, 14.495210294872672),\n",
       " 5: (22.579110466154248, 16.379016850531343),\n",
       " 6: (163.62902746536665, 450.5018663843802),\n",
       " 7: (0.43568426363561935, 37.64977619589557)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.14027772],\n",
       "       [1.18403939],\n",
       "       [1.0509067 ],\n",
       "       ...,\n",
       "       [1.23001965],\n",
       "       [1.10990205],\n",
       "       [1.09860334]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data.pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantnn.qrnn import QRNN\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~/Dendrite/Projects/IWP/GMI/training_data/try_training/qrnn_gmi_nn_esa_v0.nc\n",
      "~/Dendrite/Projects/IWP/GMI/training_data/try_training/qrnn_gmi_nn_esa_v1.nc\n",
      "~/Dendrite/Projects/IWP/GMI/training_data/try_training/qrnn_gmi_nn_esa_v2.nc\n",
      "~/Dendrite/Projects/IWP/GMI/training_data/try_training/qrnn_gmi_nn_esa_v3.nc\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in [\"0\", \"1\", \"2\", \"3\"]:\n",
    "    \n",
    "        \n",
    "    filename          = '~/Dendrite/Projects/IWP/GMI/training_data/try_training/' + \"qrnn_gmi_nn_esa_v\" + i + \".nc\"\n",
    "    print(filename)\n",
    "    qrnn              =  QRNN.load(os.path.expanduser(filename))\n",
    "    y1, y_pre1, y_pos_mean1 = get_pos_mean(validation_data, qrnn, quantiles, log = xlog)\n",
    "\n",
    "\n",
    "    outfile = os.path.basename(filename)[:-3] + \".pickle\"\n",
    "    with open(outfile, \"wb\") as f:\n",
    "\n",
    "        pickle.dump(y1, f)\n",
    "        pickle.dump(y_pre1, f)\n",
    "        pickle.dump(y_pos_mean1, f)\n",
    "        pickle.dump(validation_data.pr, f)\n",
    "\n",
    "        f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.0839931e-07, 1.1303722e-06, 1.2429388e-06, ..., 4.8364006e-04,\n",
       "        9.9657825e-04, 5.5218842e-03],\n",
       "       [5.2942872e-01, 7.6380765e-01, 7.8231150e-01, ..., 1.3973188e+00,\n",
       "        1.5708256e+00, 2.2805333e+00],\n",
       "       [5.5668652e-03, 2.9820139e-02, 6.1319686e-02, ..., 1.1254177e+00,\n",
       "        1.6050744e+00, 2.0607188e+00],\n",
       "       ...,\n",
       "       [2.2674303e-06, 8.0569898e-06, 2.0512980e-05, ..., 5.7063520e-02,\n",
       "        7.8212447e-02, 1.7998292e-01],\n",
       "       [1.9609701e-07, 3.0324186e-06, 1.5390320e-05, ..., 6.5890677e-02,\n",
       "        9.3570262e-02, 2.1237646e-01],\n",
       "       [7.9098197e-07, 1.1897635e-06, 1.6263364e-06, ..., 8.3316587e-02,\n",
       "        1.1819479e-01, 1.4632618e-01]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pre1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-46f25694d98a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pre1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimedian\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m<\u001b[0m \u001b[0;36m0.02\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhisttype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"step\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m<\u001b[0m \u001b[0;36m0.02\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhisttype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"step\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "a = y_pre1[:, imedian]\n",
    "\n",
    "plt.hist(a[y1< 0.02], bins = np.arange(0, 0.5, 0.01), histtype = \"step\")\n",
    "plt.hist(y1[y1< 0.02], bins = np.arange(0, 0.5, 0.01), histtype = \"step\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDFs of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 20})\n",
    "#bins1 = np.arange(-1, 20, 0.1)\n",
    "\n",
    "bins1 = np.array([0.0,.0001,.00025,.0005, 0.001,.0025,.005,\n",
    "                 0.0075, 0.01, 0.025, 0.05, 0.075, .1, .25,\n",
    "                 .5, .75, 1, 2, 3, 4, 5, 6, 8, 10, 12,13, 14,15 ,16, 20, 24])\n",
    "\n",
    "bin_center = (bins1[1:] + bins1[:-1])/2\n",
    "fig, axes = plt.subplots(1, 2, figsize = [12, 6])\n",
    "for ax, a, title in zip(axes.ravel(), \n",
    "                        [y_pre1[:, imedian], y_pos_mean1], \n",
    "                        ['y_median', 'y_mean']):\n",
    "    \n",
    "\n",
    "    \n",
    "    hist_y, _     = np.histogram(y1, bins1, density = True)\n",
    "    hist_y_pre, _ = np.histogram(a, bins1, density = True)\n",
    "    \n",
    "    ax.plot(bins1[1:], hist_y, label = \"observed\")\n",
    "    ax.plot(bins1[1:], hist_y_pre, label = \"predicted\")\n",
    "    \n",
    "    \n",
    "    #ax.hist(a, bins1, density = True , histtype = \"step\", label = \"QRNN\")\n",
    "    #ax.hist(np.exp(y1), bins1, density = True, histtype = \"step\", label = \"GMI\")\n",
    "    \n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xscale('log')\n",
    "    \n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "    ax.grid()\n",
    "    ax.set_ylabel(\"PDF\")\n",
    "    ax.set_xlabel(\"IWP[kg/m2]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize = [6, 6])\n",
    "rndinds = np.random.randint(1, 8000, 4000)\n",
    "for i in rndinds:\n",
    "    ax.plot(quantiles, y_pre1[i, :], 'b', alpha = 0.2)\n",
    "ax.set_xlabel(\"quantiles\")\n",
    "ax.set_ylabel(\"IWP\")\n",
    "#fig.savefig(\"quantiles.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = validation_data.x[:, :4]\n",
    "pd  = (tb[:, 0] - tb[:, 1])\n",
    "pdmask = (pd > 10)\n",
    "tbmask  = (tb[:, 0] < 230  )\n",
    "mask = np.logical_and(pdmask, tbmask) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(tb[mask, -1], pd[mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y1[mask], y_pos_mean1[mask], alpha = 0.2)\n",
    "x = np.arange(0.1, 15, 1)\n",
    "y = x\n",
    "plt.plot(x, y)\n",
    "plt.yscale(\"log\")\n",
    "plt.xscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpness(y):\n",
    "    s = np.mean((y[mask, -13 ] - y[mask, 12])/y[mask, imedian])\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(y_pre1[mask, imedian] - y1[mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize = [6, 6])\n",
    "\n",
    "for i in range(y1[mask].shape[0]):\n",
    "    ax.plot(quantiles, y_pre1[mask, :][i], 'b', alpha = 0.2)\n",
    "ax.set_xlabel(\"quantiles\")\n",
    "ax.set_ylabel(\"IWP\")\n",
    "#fig.savefig(\"quantiles.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_pre1[:, imedian], y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scatter plot of predictions vs simulated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from matplotlib import ticker, cm\n",
    "xyrange = [[0, 15], [0, 15]] # data range\n",
    "bins = [45, 45] # number of bins\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize = [12, 6])\n",
    "for ax, a, a0, title in zip(axes.ravel(), \n",
    "                     [y_pre1[:, imedian], y_pos_mean1], \n",
    "                     [y1, y1],\n",
    "                    ['y_median', 'y_mean']):\n",
    "\n",
    "   \n",
    "    hh, locx, locy = np.histogram2d(a0, a, \n",
    "                                    range=xyrange, \n",
    "                                    bins=bins, density = True)\n",
    "\n",
    "    posx = np.digitize(a0, locx)\n",
    "    posy = np.digitize(a, locy)\n",
    "    cs = ax.contourf(np.flipud(hh.T),\n",
    "                    extent=np.array(xyrange).flatten(), \n",
    "                locator= ticker.LogLocator(), origin='upper')\n",
    "    #cbar = fig.colorbar(cs)\n",
    "    ax.set_ylim([0, 12])\n",
    "    ax.set_xlim([0, 12])\n",
    "    ax.set_title(title)\n",
    "    xy = np.arange(0, 13, 1)\n",
    "    yy = xy\n",
    "    ax.plot(xy, yy)\n",
    "    ax.set_ylabel(\"IWP retrieved [kg/m2]\")\n",
    "    ax.set_xlabel(\"IWP observed [kg/m2]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### analysis of IWP fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_iwp(lat, lon, iwp0, iwp, iwp1, tb, mask):\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 3, figsize = [15, 8])\n",
    "    fig.tight_layout(pad=3.0)\n",
    "    ax = ax.ravel()\n",
    "    diff = 100 * (np.exp(np.abs(np.log(iwp/iwp0))) - 1)\n",
    "    \n",
    "    bbox = [np.min(lon),np.min(lat),np.max(lon),np.max(lat)] # set bounds for plotting\n",
    "    n_add = 0\n",
    "    m = Basemap(llcrnrlon=bbox[0]-n_add,llcrnrlat=bbox[1]-n_add,\n",
    "                urcrnrlon=bbox[2]+n_add,urcrnrlat=bbox[3]+n_add,resolution='l',\n",
    "                projection='cyl')\n",
    "    x, y = m(lon, lat)    \n",
    "    for var, axes, t in zip([iwp0, iwp, iwp1], ax, [\"Simulated\", \" y_median\", \"y_mean\"]):\n",
    "        \n",
    "        cs = axes.scatter(lon[mask],lat[mask], c = var[mask]* 1000,\n",
    "                          norm=colors.LogNorm(), vmin = 1, vmax = 10000,)\n",
    "                        # cmap = cm.Paired)\n",
    "            \n",
    "        #cs = m.scatter(lon, lat, var[mask]* 1000, ax = axes)    \n",
    "        axes.set_title(t)\n",
    "        ax[0].set_ylabel(\"Latitude [deg]\")\n",
    "        #axes.set_xlabel(\"Longitude [deg]\")\n",
    "    cbar = fig.colorbar(cs, ax=[ax[0], ax[1], ax[2]])\n",
    "    cbar.ax.set_ylabel(\"IWP [g/m2]\") \n",
    "\n",
    "def get_mask(lat, lon, latlims, lonlims):\n",
    "    \n",
    "    im  = (lat >= latlims[0]) & (lat <= latlims[1])\n",
    "    im1 = (lon >=  lonlims[0]) & (lon < lonlims[1])\n",
    "    mask  = np.logical_and(im, im1)\n",
    "    \n",
    "    return mask    \n",
    "\n",
    "def get_coords(validation_data):\n",
    "    lat = validation_data.lat\n",
    "    lon = validation_data.lon%360\n",
    "    tb  = validation_data.x[:, :5]\n",
    "    stype = validation_data.x[:, -2]\n",
    "\n",
    "    \n",
    "    return lat, lon, tb, stype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spatial analysis IWP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat1,  lon1, tb1, stype1    = get_coords(validation_data)\n",
    "lonlims = [20, 30]\n",
    "latlims = [0, 30]\n",
    "mask1 = get_mask(lat1, lon1, latlims, lonlims)\n",
    "plot_iwp(lat1, lon1, y1, y_pre1[:, imedian], y_pos_mean1, tb1, mask1)  \n",
    "\n",
    "lonlims = [0, 360]\n",
    "latlims = [-60, 60]\n",
    "mask1 = get_mask(lat1, lon1, latlims, lonlims)\n",
    "plot_iwp(lat1, lon1, y1, y_pre1[:, imedian], y_pos_mean1, tb1, mask1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare histograms of y0 - y_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(-2.5, 2.5, 0.05)\n",
    "fig, ax = plt.subplots(1, 1, figsize = [8, 6])\n",
    "hist_median, _ = np.histogram(y1 - y_pre1[:, imedian], bins, density = True)\n",
    "hist_mean, _   = np.histogram(y1 - y_pos_mean1 , bins, density = True)\n",
    "xbins = (bins[1:] + bins[:-1])/2.\n",
    "ax.plot(xbins, hist_median, label = \"y_median\")\n",
    "ax.plot(xbins, hist_mean, label = \"y_mean\")\n",
    "ax.set_yscale('log')\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"y0 - y_pre [kg m$^{-2}$]\")\n",
    "ax.set_ylabel(\"PDF\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "fig.savefig(\"PDF_IWP.png\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  associated  uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize = [6, 6])\n",
    "rndinds = np.random.randint(1, 30000, 1500)\n",
    "for i in rndinds:\n",
    "    ax.plot(quantiles, y_pre1[i, :], 'b', alpha = 0.2)\n",
    "ax.set_xlabel(\"quantiles\")\n",
    "ax.set_ylabel(\"IWP\")\n",
    "fig.savefig(\"quantiles.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize = [8, 8])\n",
    "fig.tight_layout(pad=3.0)\n",
    "\n",
    "for ax, ix, title in zip(axes.ravel(), [0, 1, 2, 3], [\"water\", \"land\", \"snow\", \"sea-ice\"]):\n",
    "    mask = stype1 == ix\n",
    "    ax.scatter(y1[mask], y_pos_mean1[mask])\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel(\"Retrieved\")\n",
    "    ax.set_xlabel(\"Simulated\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2d histogram y0 and y_pre on log scales (see ISMAR article for reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = stype1 == 0\n",
    "im1 = stype1 == 2\n",
    "xyrange = [[-5, 2], [-5, 20]]\n",
    "#xyrange = [[1e-5, 1e2], [1e-5, 1e20]]\n",
    "bins = [50, 120]\n",
    "xdat1 =  (np.log10(y_pos_mean1))\n",
    "ydat1 = (np.log10((y_pos_mean1/y1)))\n",
    "\n",
    "xdat = (np.log10(y_pre1[:, imedian]))\n",
    "ydat = (np.log10((y_pre1[:, imedian]/y1)))\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize = [12, 6])\n",
    "fig.tight_layout(pad=3.0)    \n",
    "for ax, xdt, ydt, title in zip(axes.ravel(), [xdat, xdat1], [ydat, ydat1], [\"median\", \"mean\"]):\n",
    "        \n",
    "        hh, xyrange, xdt1, ydt1 = hist2d(xdt, ydt, \n",
    "                                           bins = bins, xyrange = xyrange)\n",
    "        cs = ax.contourf(np.flipud(hh.T), \n",
    "                         levels=[0.5e-3, 1e-3,  0.5e-2, 1e-2,  0.5e-1, 1e-1, 0.5,  1e0], \n",
    "                         cmap= 'Blues',\n",
    "                extent=np.array(xyrange).flatten(), \n",
    "            locator= ticker.LogLocator(), origin='upper')\n",
    "        \n",
    "        \n",
    "        hh, xyrange, xdt1, ydt1 = hist2d(xdt[im1], ydt[im1], \n",
    "                                           bins = bins, xyrange = xyrange)\n",
    "        cs1 = ax.contour(np.flipud(hh.T), \n",
    "                         levels=[0.5e-3, 1e-3,  0.5e-2, 1e-2,  0.5e-1, 1e-1, 0.5,  1e0], \n",
    "                         cmap= 'Reds',\n",
    "                extent=np.array(xyrange).flatten(), \n",
    "            locator= ticker.LogLocator(), origin='upper')\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        hh, locx, locy = np.histogram2d(xdt, ydt, range = xyrange,\n",
    "                                     bins = bins, density = True)\n",
    "        dy = 0.5 * (locy[1:] + locy[:-1])\n",
    "        dx = 0.5 * (locx[1:] + locx[:-1])\n",
    "        off = []\n",
    "\n",
    "        for i in range(50):\n",
    "            a = np.sum(dy * hh[i, :])\n",
    "            b = np.sum(hh[i, :])\n",
    "            off.append(a/b)\n",
    "        off = np.stack(off)    \n",
    "        ax.plot(dx, off, 'k')\n",
    "        ax.set_ylim([-5, 10])\n",
    "        ax.grid('on')\n",
    "\n",
    "        ax.set_ylabel(r\"log10(y_pre / y0)]\")\n",
    "        ax.set_xlabel(r\"log10(y_pre)\")\n",
    "        ax.set_title(title)\n",
    "cbar = fig.colorbar(cs, ax = axes)  \n",
    "\n",
    "fig.savefig(\"hist2d_IWP_hlats.png\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mean fractional error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfe( y0, y):\n",
    "    return np.median(10**(np.abs(np.log10(y/y0))) - 1) * 100\n",
    "\n",
    "def calculate_mfe(y0, y):\n",
    "    nbins = 60\n",
    "    logbins = np.log10(np.logspace(np.log10(1e-4), np.log10(1e2), nbins))\n",
    "    ibins = np.digitize(np.log10(y0), logbins)\n",
    "    err = []\n",
    "    for ix in range(nbins):\n",
    "\n",
    "        ix = np.where(ibins == ix)[0]\n",
    "\n",
    "        err.append(mfe(y0[ix], y[ix]))\n",
    "    return err, logbins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre1[y_pre1<0] = 0\n",
    "err, logbins  = calculate_mfe(y1, y_pos_mean1)\n",
    "err1, _ = calculate_mfe(y1, y_pre1[:, imedian])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize = [6, 6])\n",
    "fig.tight_layout(pad=1.0)   \n",
    "\n",
    "\n",
    "ax.plot(10 ** (logbins[1:]), err[1:], '-o', label = \"mean\")\n",
    "ax.plot(10 **(logbins[1:]), err1[1:], '-o', label = \"median\")\n",
    "ax.set_ylim([0, 1000])\n",
    "ax.set_xscale(\"log\")\n",
    "#ax.set_title()\n",
    "ax.set_xlabel(r\" IWP [kg m$^{-2}$] \")\n",
    "ax.set_ylabel(\"Median fractional error [%]\")\n",
    "ax.legend()   \n",
    "ax.grid('on')\n",
    "fig.savefig(\"median_fractional_error.png\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE and BIAS over stypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y, y0):\n",
    "    return np.sqrt(np.mean((y - y0)**2))\n",
    "\n",
    "def mae(y, y0):\n",
    "    return np.mean(np.abs(y - y0))\n",
    "\n",
    "def bias(y, y0):\n",
    "    return np.mean(y - y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stype1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms = []\n",
    "rms1 = []\n",
    "\n",
    "bs = []\n",
    "bs1 = []\n",
    "stypes = [\"water\", \"land\", \"snow\", \"seaice\", \"coastlines\"]\n",
    "for ix in [0, 1, 2, 3, 4]:\n",
    "    im = stype1 == ix\n",
    "    im1 = y1 > 0.01\n",
    "    im = np.logical_and(im, im1)\n",
    "    rms.append(rmse(y_pre1[im, imedian], y1[im]))\n",
    "    rms1.append(rmse(y_pos_mean1[im], y1[im]))\n",
    "    \n",
    "    bs.append(bias(y_pre1[im, imedian], y1[im]))\n",
    "    bs1.append(bias(y_pos_mean1[im], y1[im]))\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize = [12, 8])\n",
    "x = np.arange(len(stypes))  # the label locations\n",
    "width = .20  # the width of the bars\n",
    "for ax, r, b in zip(axes.ravel(), [rms, bs], [rms1, bs1]):\n",
    "    print(r)\n",
    "    ax.bar(x - width/2, r, width = width, label = \"median\", color = \"tab:blue\")\n",
    "    ax.bar(x + width/2, b, width = width, label = \"mean\", color = \"tab:orange\")\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(stypes)\n",
    "    ax.legend()\n",
    "    ax.grid(\"on\")\n",
    "axes[0].set_ylabel(r\"RMSE [kg m$^{-2}$]\")\n",
    "axes[1].set_ylabel(r\"Bias [kg m$^{-2}$]\")\n",
    "\n",
    "fig.suptitle(\"statistics for IWP >= 0.01 kg/m2\")\n",
    "fig.savefig(\"RMSE_bias_hlats.png\", bbox_inches = \"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms = []\n",
    "rms1 = []\n",
    "\n",
    "bs = []\n",
    "bs1 = []\n",
    "stypes = [\"water\", \"land\", \"snow\", \"seaice\", \"coastlines\"]\n",
    "for ix in [0, 1, 2, 3, 4]:\n",
    "    im = stype1 == ix\n",
    "    #im1 = y1 > 0.01\n",
    "    #im = np.logical_and(im, im1)\n",
    "    rms.append(rmse(y_pre1[im, imedian], y1[im]))\n",
    "    rms1.append(rmse(y_pos_mean1[im], y1[im]))\n",
    "    \n",
    "    bs.append(bias(y_pre1[im, imedian], y1[im]))\n",
    "    bs1.append(bias(y_pos_mean1[im], y1[im]))\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize = [12, 8])\n",
    "x = np.arange(len(stypes))  # the label locations\n",
    "width = .20  # the width of the bars\n",
    "for ax, r, b in zip(axes.ravel(), [rms, bs], [rms1, bs1]):\n",
    "    print(r)\n",
    "    ax.bar(x - width/2, r, width = width, label = \"median\", color = \"tab:blue\")\n",
    "    ax.bar(x + width/2, b, width = width, label = \"mean\", color = \"tab:orange\")\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(stypes)\n",
    "    ax.legend()\n",
    "    ax.grid(\"on\")\n",
    "axes[0].set_ylabel(r\"RMSE [kg m$^{-2}$]\")\n",
    "axes[1].set_ylabel(r\"Bias [kg m$^{-2}$]\")\n",
    "\n",
    "fig.suptitle(\"statistics for all IWP\")\n",
    "fig.savefig(\"RMSE_bias_hlats_all.png\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error over IWP bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nbins = 50\n",
    "logbins = np.logspace(np.log10(1e-3), np.log10(0.5e2), nbins)\n",
    "ibins = np.digitize(y1, logbins)\n",
    "counts = np.bincount(ibins)\n",
    "ntrue = []\n",
    "for j in range(nbins):\n",
    "    itrue = ([i for i in range(y1.shape[0]) if y1[i] >= y_pre1[i, 0] if y1[i] <= y_pre1[i, -1] if ibins[i] == j])\n",
    "    ntrue.append(len(itrue))\n",
    "ntrue = np.array(ntrue)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize = [6, 6])\n",
    "ax.plot(logbins[:len(counts)], 100 * ntrue[:len(counts)]/counts, '-o')\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_xlabel(\"IWP [kg/m2]\")\n",
    "ax.set_ylabel(\"% true occurences in 98% CI\")\n",
    "ax.grid('on')\n",
    "ax.set_ylim([0, 100])\n",
    "fig.savefig(\"Uncertainty_IWP.png\", bbox_inches = \"tight\") \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins = 50\n",
    "logbins = np.logspace(np.log10(1e-8), np.log10(0.5e2), nbins)\n",
    "ibins = np.digitize(y1, logbins)\n",
    "imatrix = np.zeros([nbins, nbins])\n",
    "ibins_p = np.digitize(y_pos_mean1, logbins)\n",
    "\n",
    "\n",
    "for i in range(ibins.max()):\n",
    "    in2 = ibins_p[ibins == i].max()\n",
    "    ib = np.bincount(ibins_p[ibins == i])\n",
    "    imatrix[ :in2 + 1, i] = 100 * ib/np.sum(ibins == 1)\n",
    "    \n",
    "fig, ax = plt.subplots(1, 1, figsize = [7, 6])\n",
    "imatrix[imatrix == 0] = np.nan\n",
    "cs = ax.pcolormesh(logbins, logbins, imatrix, cmap='Blues', vmin = 0, vmax = 50)\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "x = logbins\n",
    "y = x\n",
    "ax.plot(x, y, alpha = 0.1)\n",
    "fig.colorbar(cs)\n",
    "ax.set_xlabel(\"IWP simulated [kg/m2]\")\n",
    "ax.set_ylabel(\"IWP retrieved [kg/m2]\")\n",
    "ax.set_xlim(1e-8, 50)\n",
    "ax.set_ylim(1e-8, 50)\n",
    "fig.savefig(\"histogram2d_IWP.png\", bbox_inches = \"tight\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check false hits/misses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iwplim = 0.01 #[kg/m2]\n",
    "\n",
    "falsemiss = y1[y_pos_mean1 <= iwplim] >= iwplim\n",
    "\n",
    "falsehits = y_pos_mean1[y1 <= iwplim] >= iwplim\n",
    "\n",
    "print(\"falsemiss among total data : \", np.sum(falsemiss)/y1.shape[0], \"\\n\",\n",
    "      \"falsehits among total data : \", np.sum(falsehits)/y1.shape[0])\n",
    "\n",
    "\n",
    "print(\"falsemiss among IWP < 0.01 kg/m2 : \", np.sum(falsemiss)/np.sum(y1[y_pos_mean1 <= iwplim]), \"\\n\",\n",
    "      \"falsehits among IWP < 0.01 kg/m2 : \", np.sum(falsehits)/np.sum(y_pos_mean1[y1 <= iwplim]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pos_mean1.min()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logbins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile1 = \"qrnn_gmi_all_z0_log10.pickle\"\n",
    "outfile2 = \"qrnn_gmi_all_z0.pickle\"\n",
    "outfile3 = \"qrnn_gmi_all_z0_linear.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pickle(file):\n",
    "    with open(file, \"rb\") as f:\n",
    "        y      = pickle.load(f)\n",
    "        y_pre  = pickle.load(f)\n",
    "        y_mean = pickle.load(f)\n",
    "        f.close()\n",
    "        \n",
    "    return y, y_pre, y_mean\n",
    "\n",
    "y1, y_pre1, y_mean1  = read_pickle(outfile1)\n",
    "y2, y_pre2, y_mean2  = read_pickle(outfile2)\n",
    "y3, y_pre3, y_mean3  = read_pickle(outfile3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(y1, y_pre1, y_pos_mean1):\n",
    "    rms = []\n",
    "    rms1 = []\n",
    "\n",
    "    bs = []\n",
    "    bs1 = []\n",
    "    stypes = [\"water\", \"land\", \"snow\", \"seaice\", \"coastlines\"]\n",
    "    for ix in [0, 1, 2, 3, 4]:\n",
    "        im = stype1 == ix\n",
    "        #im1 = y1 > 0.01\n",
    "        #im = np.logical_and(im, im1)\n",
    "        rms.append(rmse(y_pre1[im, imedian], y1[im]))\n",
    "        rms1.append(rmse(y_pos_mean1[im], y1[im]))\n",
    "\n",
    "        bs.append(bias(y_pre1[im, imedian], y1[im]))\n",
    "        bs1.append(bias(y_pos_mean1[im], y1[im]))\n",
    "        \n",
    "    return rms, bs   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stypes = [\"water\", \"land\", \"snow\", \"seaice\", \"coastlines\"]\n",
    "rms1, bs1 = stats(y1, y_pre1, y_mean1)\n",
    "rms2, bs2 = stats(y2, y_pre2, y_mean2)\n",
    "rms3, bs3 = stats(y3, y_pre3, y_mean3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0, len(stypes), 1)\n",
    "width = 0.15\n",
    "fig, ax = plt.subplots(1, 1, figsize = [10, 6])\n",
    "ax.bar(x - 0.2, rms1, width,  label = \"log10\")\n",
    "ax.bar(x , rms2, width, label = \"log\")\n",
    "ax.bar(x + 0.2, rms3, width, label = \"linear\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(stypes)\n",
    "ax.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0, len(stypes), 1)\n",
    "width = 0.15\n",
    "fig, ax = plt.subplots(1, 1, figsize = [10, 6])\n",
    "ax.bar(x - 0.2, bs1, width,  label = \"log10\")\n",
    "ax.bar(x , bs2, width, label = \"log\")\n",
    "ax.bar(x + 0.2, bs3, width, label = \"linear\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(stypes)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err1, logbins  = calculate_mfe(y1, y_mean1)\n",
    "err2, _        = calculate_mfe(y2, y_mean2)\n",
    "err3, _        = calculate_mfe(y3, y_mean3)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize = [6, 6])\n",
    "fig.tight_layout(pad=1.0)   \n",
    "\n",
    "\n",
    "ax.plot(10 ** (logbins[1:]), err1[1:], '-o', label = \"log10\")\n",
    "ax.plot(10 **(logbins[1:]), err2[1:], '-o', label = \"log\")\n",
    "ax.plot(10 **(logbins[1:]), err3[1:], '-o', label = \"linear\")\n",
    "ax.set_ylim([0, 1000])\n",
    "ax.set_xscale(\"log\")\n",
    "#ax.set_title()\n",
    "ax.set_xlabel(r\" IWP [kg m$^{-2}$] \")\n",
    "ax.set_ylabel(\"Median fractional error [%]\")\n",
    "ax.legend()   \n",
    "ax.grid('on')\n",
    "fig.savefig(\"median_fractional_error.png\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_events(y1, y_pre1):\n",
    "    nbins = 50\n",
    "    logbins = np.logspace(np.log10(1e-3), np.log10(0.5e2), nbins)\n",
    "    ibins = np.digitize(y1, logbins)\n",
    "    counts = np.bincount(ibins)\n",
    "    ntrue = []\n",
    "    for j in range(nbins):\n",
    "        itrue = ([i for i in range(y1.shape[0]) if y1[i] >= y_pre1[i, 0] if y1[i] <= y_pre1[i, -1] if ibins[i] == j])\n",
    "        ntrue.append(len(itrue))\n",
    "    ntrue = np.array(ntrue)\n",
    "    \n",
    "    return ntrue, counts, logbins\n",
    "\n",
    "\n",
    "ntrue1, counts1, logbins = true_events(y1, y_pre1)\n",
    "ntrue2, counts2, _ = true_events(y2, y_pre2)\n",
    "ntrue3, counts3, _ = true_events(y3, y_pre3)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize = [6, 6])\n",
    "ax.plot(logbins[:len(counts1)], 100 * ntrue1[:len(counts1)]/counts1, '-o', label = \"log10\")\n",
    "ax.plot(logbins[:len(counts2)], 100 * ntrue2[:len(counts2)]/counts2, '-o', label = \"log\")\n",
    "ax.plot(logbins[:len(counts3)], 100 * ntrue3[:len(counts3)]/counts3, '-o', label = \"linear\")\n",
    "\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_xlabel(\"IWP [kg/m2]\")\n",
    "ax.set_ylabel(\"% true occurences in 98% CI\")\n",
    "ax.grid('on')\n",
    "ax.set_ylim([60, 100])\n",
    "ax.legend()\n",
    "fig.savefig(\"Uncertainty_IWP.png\", bbox_inches = \"tight\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import ipywidgets as w\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import netCDF4\n",
    "from matplotlib.ticker import (MultipleLocator, FormatStrFormatter,\n",
    "                               AutoMinorLocator)\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from iwc2tb.GMI.gmiData import gmiData\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typhon.retrieval.qrnn import set_backend, QRNN\n",
    "set_backend(\"pytorch\")\n",
    "\n",
    "#quantiles         = np.array([0.002, 0.03, 0.16, 0.5, 0.84, 0.97, 0.998])\n",
    "quantiles         = np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "\n",
    "batchSize         = 256\n",
    "\n",
    "depth             = 4\n",
    "width             = 256\n",
    "convergence_epoch = 5\n",
    "maximum_epoch     = 40\n",
    "\n",
    "inputs            = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inChannels = np.array(['166.5V', '166.5H', '183+-3', '183+-7'], dtype=object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(depth, width, batchSize, convergence_epoch, maximum_epoch, training_data, validation_data):\n",
    "        qrnn = QRNN(inputs, quantiles, (depth, width , \"relu\"))\n",
    "        for lr in [  0.01, 0.001, 0.0001]:\n",
    "            print (\"NEW LEARNING RATE\")\n",
    "            results = qrnn.train(\n",
    "                training_data,\n",
    "                validation_data,\n",
    "                batch_size=batchSize,\n",
    "                momentum = 0,\n",
    "                sigma_noise=None,\n",
    "                initial_learning_rate= lr ,\n",
    "                maximum_epochs=maximum_epoch,\n",
    "                convergence_epochs= convergence_epoch,    \n",
    "                gpu=True)\n",
    "\n",
    "        return results, qrnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = gmiData(os.path.expanduser(\"~/Dendrite/Projects/IWP/GMI/training_data/TB_GMI_train.nc\"), inChannels,\n",
    "               batch_size = batchSize) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW LEARNING RATE\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6bd43d2cb264cc396e941f885b9d3b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3666.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " \n",
    "\n",
    "n = len(data)\n",
    "n_train = int(0.9 * n)\n",
    "n_val = n - n_train\n",
    "\n",
    "training_data, validation_data = random_split(data, [n_train, n_val])\n",
    "results = []\n",
    "\n",
    "results, qrnn = train(depth, width, batchSize, convergence_epoch, maximum_epoch, training_data, validation_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrnn.save('try/qrnn_gmi_iwp.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(results['training_errors'])\n",
    "ax.plot(results['validation_errors'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot calibration plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrnn =  QRNN.load('try/qrnn_gmi_iwp.nc')\n",
    "x, y = qrnn.calibration(validation_data)\n",
    "f, ax = plt.subplots(1, 1)\n",
    "ax.plot(x, y, marker = \"o\", c = 'r')\n",
    "ax.plot(x, x, ls = \":\", c = \"k\")\n",
    "#ax.set_xlim([0.1, 0.9])\n",
    "#ax.set_ylim([0.1, 0.9])\n",
    "ax.set_aspect(1.0)\n",
    "ax.set_xlabel(\"Predicted frequency\")\n",
    "ax.set_ylabel(\"Observed frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre = []\n",
    "y = []\n",
    "y_prior = []\n",
    "y_pos_mean = []\n",
    "x_in = []\n",
    "\n",
    "nbatch = validation_data.__len__()\n",
    "print (nbatch)\n",
    "for i in range(nbatch):\n",
    "    \n",
    "    xx, yy = validation_data.__getitem__(i)\n",
    "    \n",
    "    x = xx.detach().numpy() \n",
    "\n",
    "    y_pre.append(qrnn.predict(x)) \n",
    "    y_pos_mean.append((qrnn.posterior_mean(x)))\n",
    "       \n",
    "    y.append(yy.detach().numpy())\n",
    "    x_in.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_in = np.concatenate(x_in, axis = 0)\n",
    "y_pre = np.concatenate(y_pre, axis = 0)\n",
    "y = np.concatenate(y, axis= 0)\n",
    "y_pos_mean = np.concatenate(y_pos_mean, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 20})\n",
    "bins1 = np.arange(0, 10, 0.1)\n",
    "fig, ax = plt.subplots(1, 1, figsize = [8, 8])\n",
    "ax.hist(y_pos_mean, bins1, density = True , histtype = \"step\", label = \"predicted\")\n",
    "\n",
    "\n",
    "ax.hist(y, bins1, density = True, histtype = \"step\", label = \"actual\")\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "\n",
    "ax.legend()\n",
    "ax.set_ylabel(\"PDF\")\n",
    "ax.set_xlabel(\"IWP[kg/m2]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from matplotlib import ticker, cm\n",
    "xyrange = [[0, 15], [0, 15]] # data range\n",
    "\n",
    "bins = [30, 30] # number of bins\n",
    "hh, locx, locy = np.histogram2d(y, y_pos_mean, \n",
    "                                range=xyrange, bins=bins, density = True)\n",
    "posx = np.digitize(y, locx)\n",
    "posy = np.digitize(y_pos_mean, locy)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize = [10, 8])\n",
    "cs = ax.contourf(np.flipud(hh.T),\n",
    "                extent=np.array(xyrange).flatten(), \n",
    "            locator= ticker.LogLocator(), origin='upper')\n",
    "cbar = fig.colorbar(cs)\n",
    "ax.set_ylim([0, 12])\n",
    "ax.set_xlim([0, 12])\n",
    "xy = np.arange(0, 13, 1)\n",
    "yy = xy\n",
    "ax.plot(xy, yy)\n",
    "ax.set_ylabel(\"IWP Predicted [kg/m2]\")\n",
    "ax.set_xlabel(\"IWP Observed [kg/m2]\")\n",
    "#ax.set_yscale('log')\n",
    "#ax.set_xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
